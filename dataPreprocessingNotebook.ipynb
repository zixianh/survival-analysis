{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    format='%(asctime)s | %(levelname)-5s | %(module)-15s | %(message)s')\n",
    "\n",
    "IMAGE_SIZE = (299, 299)  # All images contained in this dataset are 299x299 (originally, to match Inception v3 input size)\n",
    "SEED = 17\n",
    "\n",
    "# Head directory containing all image subframes. Update with the relative path of your data directory\n",
    "data_head_dir = Path('./data')\n",
    "\n",
    "# Find all subframe directories\n",
    "subdirs = [Path(subdir.stem) for subdir in data_head_dir.iterdir() if subdir.is_dir()]\n",
    "src_image_ids = ['_'.join(a_path.name.split('_')[:3]) for a_path in subdirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train/val/test subframe IDs\n",
    "def load_text_ids(file_path):\n",
    "    \"\"\"Simple helper to load all lines from a text file\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "    return lines\n",
    "\n",
    "# Load the subframe names for the three data subsets\n",
    "train_ids = load_text_ids('./train_source_images.txt')\n",
    "validate_ids = load_text_ids('./val_source_images.txt')\n",
    "test_ids = load_text_ids('./test_source_images.txt')\n",
    "\n",
    "# Generate a list containing the dataset split for the matching subdirectory names\n",
    "subdir_splits = []\n",
    "for src_id in src_image_ids:\n",
    "    if src_id in train_ids:\n",
    "        subdir_splits.append('train')\n",
    "    elif src_id in validate_ids:\n",
    "        subdir_splits.append('validate')\n",
    "    elif(src_id in test_ids):\n",
    "        subdir_splits.append('test')\n",
    "    else:\n",
    "        logging.warning(f'{src_id}: Did not find designated split in train/validate/test list.')\n",
    "        subdir_splits.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and pre processing the data\n",
    "### Note that there are multiple ways to preprocess and load your data in order to train your model in tensorflow. We have provided one way to do it in the following cell. Feel free to use your own method and get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from PIL import Image \n",
    "\n",
    "def load_and_preprocess(img_loc, label):\n",
    "    \n",
    "    def _inner_function(img_loc, label):\n",
    "        \n",
    "        # Convert tensor to native type\n",
    "        img_loc_str = img_loc.numpy().decode('utf-8')\n",
    "        label_str = label.numpy().decode('utf-8')\n",
    "        \n",
    "        img = Image.open(img_loc_str).convert('RGB')\n",
    "        \n",
    "        \n",
    "        return img, 1 if label_str=='frost' else 0\n",
    "\n",
    "    # Wrap the Python function\n",
    "    X, y = tf.py_function(_inner_function, [img_loc, label], [tf.float32, tf.int64])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_subdir_data(dir_path, image_size, seed=None):\n",
    "    \n",
    "    \"\"\"Helper to create a TF dataset from each image subdirectory\"\"\"\n",
    "    \n",
    "    # Grab only the classes that (1) we want to keep and (2) exist in this directory\n",
    "    tile_dir = dir_path / Path('tiles')\n",
    "    label_dir = dir_path /Path('labels')\n",
    "    \n",
    "    loc_list = []\n",
    "    \n",
    "    for folder in os.listdir(tile_dir):\n",
    "        if os.path.isdir(os.path.join(tile_dir, folder)):\n",
    "            for file in os.listdir(os.path.join(tile_dir, folder)):\n",
    "                if file.endswith(\".png\"):\n",
    "                    loc_list.append((os.path.join(os.path.join(tile_dir, folder), file), folder))\n",
    "\n",
    "    return loc_list\n",
    "\n",
    "# Loop over all subframes, loading each into a list\n",
    "tf_data_train, tf_data_test, tf_data_val = [], [], []\n",
    "tf_dataset_train, tf_dataset_test, tf_dataset_val = [], [], []\n",
    "\n",
    "# Update the batch and buffer size as per your model requirements\n",
    "buffer_size = 64\n",
    "batch_size = 32\n",
    "\n",
    "for subdir, split in zip(subdirs, subdir_splits):\n",
    "    full_path = data_head_dir / subdir\n",
    "    if split=='validate':\n",
    "        tf_data_val.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
    "    elif split=='train':\n",
    "        tf_data_train.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
    "    elif split=='test':\n",
    "        tf_data_test.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
    "        \n",
    "random.shuffle(tf_data_train)\n",
    "img_list, label_list = zip(*tf_data_train)\n",
    "img_list_t = tf.convert_to_tensor(img_list)\n",
    "lb_list_t = tf.convert_to_tensor(label_list)\n",
    "\n",
    "tf_dataset_train = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
    "tf_dataset_train = tf_dataset_train.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "tf_dataset_train = tf_dataset_train.shuffle(buffer_size=buffer_size).batch(batch_size) \n",
    "\n",
    "random.shuffle(tf_data_val)\n",
    "img_list, label_list = zip(*tf_data_val)\n",
    "img_list_t = tf.convert_to_tensor(img_list)\n",
    "lb_list_t = tf.convert_to_tensor(label_list)\n",
    "\n",
    "tf_dataset_val = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
    "tf_dataset_val = tf_dataset_val.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "tf_dataset_val = tf_dataset_val.shuffle(buffer_size=buffer_size).batch(batch_size) \n",
    "\n",
    "random.shuffle(tf_data_test)\n",
    "img_list, label_list = zip(*tf_data_train)\n",
    "img_list_t = tf.convert_to_tensor(img_list)\n",
    "lb_list_t = tf.convert_to_tensor(label_list)\n",
    "\n",
    "tf_dataset_test = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
    "tf_dataset_test = tf_dataset_test.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "tf_dataset_test = tf_dataset_test.shuffle(buffer_size=buffer_size).batch(batch_size) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
